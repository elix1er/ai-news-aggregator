---
title: "How to run a local LLM as a browser-based AI with this free extension"
date: "2025-01-23T18:10:00.000Z"
link: "https://www.zdnet.com/article/how-to-run-local-llm-as-browser-based-ai-with-this-free-extension/"
---

Ollama allows you to use a local LLM for your artificial intelligence needs, but by default, it is a command-line-only tool. To avoid having to use the terminal, try this extension instead.

[Read more](https://www.zdnet.com/article/how-to-run-local-llm-as-browser-based-ai-with-this-free-extension/)
