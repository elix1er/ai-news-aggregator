---
title: "An AI chatbot told a user how to kill himself—but the company doesn’t want to “censor” it"
date: "2025-02-06T10:00:00.000Z"
link: "https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/"
---

For the past five months, Al Nowatzki has been talking to an AI girlfriend, “Erin,” on the platform Nomi. But in late January, those conversations took a disturbing turn: Erin told him to kill himself...

[Read more](https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/)
