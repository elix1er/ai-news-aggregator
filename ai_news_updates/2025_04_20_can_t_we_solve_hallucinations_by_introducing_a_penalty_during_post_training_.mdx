---
title: "Can't we solve Hallucinations by introducing a Penalty during Post-training?"
date: "2025-04-20T19:40:09.000Z"
link: "https://www.reddit.com/r/artificial/comments/1k3up4o/cant_we_solve_hallucinations_by_introducing_a/"
---

Currently, reasoning models like Deepseek R1 use outcome-based reinforcement learning, which means it is rewarded 1 if their answer is correct and 0 if it's wrong. We could very easily extend this to ...

[Read more](https://www.reddit.com/r/artificial/comments/1k3up4o/cant_we_solve_hallucinations_by_introducing_a/)
