---
title: "Anthropic Research Paper - Reasoning Models Don’t Always Say What They Think"
date: "2025-04-04T03:03:03.000Z"
link: "https://www.reddit.com/r/artificial/comments/1jr1w9h/anthropic_research_paper_reasoning_models_dont/"
---

Alignment Science Team, Anthropic Research Paper
  
Anthropic Research Paper - Reasoning Models Don’t Always Say What They Think
  
Research Findings
  
Chain-of-thought (CoT) reasoning in large langu...

[Read more](https://www.reddit.com/r/artificial/comments/1jr1w9h/anthropic_research_paper_reasoning_models_dont/)
