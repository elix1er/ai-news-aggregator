---
title: "Tensormesh raises $4.5M to squeeze more inference out of AI server loads"
date: "2025-10-23T16:00:00.000Z"
link: "https://techcrunch.com/2025/10/23/tensormesh-raises-4-5m-to-squeeze-more-inference-out-of-ai-server-loads/"
---

Tensormesh uses an expanded form of KV caching to make inference loads as much as 10 times more efficient.

[Read more](https://techcrunch.com/2025/10/23/tensormesh-raises-4-5m-to-squeeze-more-inference-out-of-ai-server-loads/)
